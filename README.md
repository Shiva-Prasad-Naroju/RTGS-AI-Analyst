# RTGS AI Analyst

âš¡ From raw data to polished insights â€” fully automated with AI-driven cleaning, transformation, and reporting.

## Overview
RTGS AI Analyst **automates** the full data quality lifecycle â€” ingestion, cleaning, transformation, and validation. It detects issues, applies fixes, and ensures datasets are **analysis-ready.**
Finally, it delivers clear **visualizations** and **professional AI-driven reports.**

## ğŸŒŸ Key Features
- **Supervisor-Agent Orchestration**: Orchestrator for the whole pipeline.
- **Modular Multi-Agent Workflow**:
  - Ingestion â†’ Inspection â†’ Cleaning â†’ Transformation â†’ Verification â†’ Analysis â†’ Visualization â†’ Reporting
- **Rule-Based + LLM Hybrid**:
  - Deterministic checks for missing values, duplicates, data types, outliers.
  - **LLM-powered insights with Groq LLaMA-3.1-8B-Instant** (Analysis Agent).
- **Executive Summaries**: Auto-generated stakeholder-friendly reports.
- **CLI Support**: Run complete pipeline with a single command.


## ğŸš€ RTGS AI Analyst - Workflow

```mermaid
flowchart TD
    A[ğŸ“‚ Ingestion Agent] --> B[ğŸ” Inspection Agent]
    B --> C[ğŸ§¹ Cleaning Agent]
    C -->|apply_transformations=True| D[ğŸ”§ Transformation Agent]
    C -->|apply_transformations=False| E[â­ï¸ Skip Transformation]
    D --> F[âœ… Verification Agent]
    E --> F[âœ… Verification Agent]
    F --> G[ğŸ“Š Analysis Agent]
    G -->|create_visualizations=True| H[ğŸ“ˆ Visualization Agent]
    G -->|create_visualizations=False| I[â­ï¸ Skip Visualization]
    H --> J[ğŸ“ Report Agent]
    I --> J[ğŸ“ Report Agent]
    J --> K[ğŸ’¾ Save Final Datasets]
```

## âœ¨ Key Features
1. **ğŸ” Ingestion Agent** - Loads and validates datasets (CSV, XLSX)
2. **ğŸ” Inspection Agent** - Identifies data quality issues and vulnerabilities  
3. **ğŸ§¹ Cleaning Agent** - Handles missing values, duplicates, outliers
4. **ğŸ”„ Transformation Agent** - Applies encoding, scaling, feature engineering
5. **âœ… Verification Agent** - Validates final data quality and consistency
6. **ğŸ§  Analysis Agent** - Generates AI-powered insights and recommendations
7. **ğŸ“Š Visualization Agent** - Creates comparison charts and exports to PDF
8. **ğŸ“‹ Report Agent** - Produces professional step-by-step analysis reports


## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- pip or uv package manager

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/Shiva-Prasad-Naroju/RTGS-AI-Analyst.git
cd RTGS-AI-Analyst
```

2. **Install dependencies:**
```bash
# Using pip
pip install -r requirements.txt

# Using uv (recommended)
uv add -r requirements.txt
```

3. **Set up API keys (optional but recommended):**
```bash
# For ChatGroq (recommended - faster and cheaper)
export GROQ_API_KEY="your_groq_api_key"

# Or OpenAI (fallback)
export OPENAI_API_KEY="your_openai_api_key"
```

4. **Create virtual environment (recommended)**
```bash
python -m venv venv

# On Windows
venv\Scripts\activate

# On macOS/Linux
source venv/bin/activate
```

### Basic Usage

1. **Using Default Dataset**
   ```bash
   python main.py
   ```
   *Uses `data/raw/agricultural_2019_5.csv` if available*

2. **Using Custom Dataset**
   ```bash
   python main.py --file path/to/your/dataset.csv
   ```


## ğŸ“š Usage Examples

### Complete Pipeline
```bash
# Full analysis with all features
python main.py --file sales_data.csv
```

### Customized Pipeline
```bash
# Skip transformations and visualizations
python main.py --file data.csv --no-transformations --no-visualizations

# Only data cleaning and analysis
python main.py --file data.csv --no-report

# Fully automated processing
python main.py --file large_dataset.csv --non-interactive
```


## ğŸ“ Project Structure

```
rtgs-ai-analyst/
â”œâ”€â”€ main.py                 # Main entry point and CLI
â”œâ”€â”€ config.py              # Configuration settings
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md             
â”œâ”€â”€ utils.py
â”œâ”€â”€ agents/               # AI Agent modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ingestion_agent.py
â”‚   â”œâ”€â”€ inspection_agent.py
â”‚   â”œâ”€â”€ cleaning_agent.py
â”‚   â”œâ”€â”€ transformation_agent.py
â”‚   â”œâ”€â”€ verification_agent.py
â”‚   â”œâ”€â”€ analysis_agent.py
â”‚   â”œâ”€â”€ visualization_agent.py
â”‚   â””â”€â”€ report_agent.py
â”œâ”€â”€ utils/               # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_utils.py
â”‚   â”œâ”€â”€ file_utils.py
â”‚   â””â”€â”€ logging_utils.py
â”œâ”€â”€ 
â”œâ”€â”€ data/               # Data directories
â”‚   â”œâ”€â”€ raw/           # Input datasets
â”‚   â””â”€â”€ processed/     # Cleaned datasets
â”œâ”€â”€ 
â”œâ”€â”€ outputs/           # Generated outputs
â”‚   â”œâ”€â”€ reports/       # Analysis reports
â”‚   â””â”€â”€ visualizations/ # Chart PDFs
â””â”€â”€ 
```

## Sample Output

### Data Quality & Trends
![Data Quality Chart](./output_chart.png)

### Generated Report
![Analysis Report](./output_report.png)


## âš™ï¸ Configuration

### Supported File Formats

- **CSV Files**: `.csv`
- **Excel Files**: `.xlsx`, `.xls` 
- **JSON Files**: `.json`
- **Parquet Files**: `.parquet`

### Pipeline Options

| Option | Description | Default |
|--------|-------------|---------|
| `--file` | Input dataset path | `data/raw/agricultural_2019_5.csv` |
| `--no-transformations` | Skip transformation step | False |
| `--no-visualizations` | Skip visualization creation | False |
| `--no-report` | Skip report generation | False |
| `--non-interactive` | Automated mode | False |
| `--output-dir` | Custom output directory | Default paths |

### Quality Score Interpretation

- **ğŸŸ¢ 90-100**: Excellent data quality
- **ğŸŸ¡ 75-89**: Good data quality  
- **ğŸŸ  60-74**: Acceptable data quality
- **ğŸ”´ <60**: Needs improvement


## ğŸ“Š Pipeline Stages

### 1. Data Ingestion
- Automatic format detection
- Memory-optimized loading
- Error handling and validation

### 2. Quality Inspection
- Missing value analysis
- Duplicate detection
- Data type validation
- Statistical anomaly identification

### 3. Data Cleaning
- Intelligent missing value imputation
- Duplicate removal strategies
- Outlier treatment
- Data type corrections

### 4. Data Transformation
- Feature engineering
- Encoding categorical variables
- Normalization and scaling
- Derived feature creation

### 5. Quality Verification
- Post-cleaning quality assessment
- Improvement metric calculation
- Data integrity validation

### 6. AI-Powered Analysis
- Statistical analysis
- Pattern recognition
- Insight generation
- Correlation analysis

### 7. Visualization Generation
- Automated chart selection
- Dynamic visualization creation
- PDF report compilation

### 8. Report Generation
- Comprehensive analysis summary
- Quality improvement metrics
- Actionable recommendations


## Acknowledgments

- Built with Python, langchain, GROQ inference.
- Thanks to the open-source community for excellent libraries





